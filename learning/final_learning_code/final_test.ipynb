{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../face-4263.png\n",
      "예측: sunglasses_074.png\n",
      "Happy\n",
      "해당 사진은 선글라스를 썼습니다.\n",
      "#####################################\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.preprocessing.image import ImageDataGenerator, load_img\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Activation, BatchNormalization\n",
    "import random\n",
    "import os\n",
    "import natsort\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from imutils.face_utils import FaceAligner\n",
    "from imutils.face_utils import rect_to_bb\n",
    "import imutils\n",
    "import dlib\n",
    "import cv2 \n",
    "\n",
    "predictor_model = \"./landmarks.dat\"\n",
    "\n",
    "# initialize dlib's face detector (HOG-based) and then create\n",
    "# the facial landmark predictor and the face aligner\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(predictor_model)\n",
    "fa = FaceAligner(predictor, desiredFaceWidth=256)\n",
    "\n",
    "def face_align(image):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    rects = detector(gray, 2)\n",
    "\n",
    "    for rect in rects:\n",
    "        (x, y, w, h) = rect_to_bb(rect)\n",
    "        faceOrig = imutils.resize(image[y:y + h, x:x+w], width=256)\n",
    "        faceAligned = fa.align(image, gray, rect)\n",
    "        return faceAligned\n",
    "\n",
    "##################################################################\n",
    "\n",
    "# Define constants\n",
    "FAST_RUN = False\n",
    "IMAGE_WIDTH = 48\n",
    "IMAGE_HEIGHT = 48\n",
    "IMAGE_SIZE=(IMAGE_WIDTH, IMAGE_HEIGHT)\n",
    "IMAGE_CHANNELS=1\n",
    "PIXELS = IMAGE_HEIGHT * IMAGE_WIDTH*3\n",
    "\n",
    "# Create the model\n",
    "model_emotion = Sequential()\n",
    "model_emotion.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(48,48,1)))\n",
    "model_emotion.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "model_emotion.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model_emotion.add(Dropout(0.25))\n",
    "model_emotion.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "model_emotion.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model_emotion.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "model_emotion.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model_emotion.add(Dropout(0.25))\n",
    "model_emotion.add(Flatten())\n",
    "model_emotion.add(Dense(1024, activation='relu'))\n",
    "model_emotion.add(Dropout(0.5))\n",
    "model_emotion.add(Dense(7, activation='softmax'))\n",
    "model_emotion.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "model_emotion.load_weights(\"emotion_model.h5\")\n",
    "#####################################################################\n",
    "\n",
    "model_mask1 = Sequential()\n",
    "model_mask1.add(Conv2D(32, kernel_size=(3, 3), activation = 'relu', input_shape = (128, 128, 3)))\n",
    "model_mask1.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model_mask1.add(Dropout(0.5))\n",
    "model_mask1.add(Conv2D(64,kernel_size=(3, 3), activation='relu'))\n",
    "model_mask1.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model_mask1.add(Dropout(0.5))\n",
    "model_mask1.add(Conv2D(128,kernel_size=(3, 3), activation='relu'))\n",
    "model_mask1.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model_mask1.add(Dropout(0.5))\n",
    "model_mask1.add(Flatten())\n",
    "model_mask1.add(Dense(512, activation='relu'))\n",
    "model_mask1.add(Dropout(0.5))\n",
    "model_mask1.add(Dense(2, activation = 'sigmoid'))\n",
    "model_mask1.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "model_mask1.load_weights(\"mask_model_5.h5\")\n",
    "\n",
    "#####################################################################\n",
    "model_glasses1 = Sequential()\n",
    "\n",
    "model_glasses1.add(Conv2D(32, kernel_size=(3, 3), strides = (1,1), padding = 'same', activation = 'relu', input_shape = (128, 128, 3)))\n",
    "model_glasses1.add(BatchNormalization())\n",
    "model_glasses1.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model_glasses1.add(Dropout(0.25))\n",
    "\n",
    "model_glasses1.add(Conv2D(64,kernel_size=(3, 3), strides = (1,1),  padding = 'same', activation='relu'))\n",
    "model_glasses1.add(BatchNormalization())\n",
    "model_glasses1.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model_glasses1.add(Dropout(0.25))\n",
    "\n",
    "model_glasses1.add(Conv2D(128,kernel_size=(3, 3), strides = (1,1),  padding = 'same', activation='relu'))\n",
    "model_glasses1.add(BatchNormalization())\n",
    "model_glasses1.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model_glasses1.add(Dropout(0.25))\n",
    "\n",
    "model_glasses1.add(Flatten())\n",
    "model_glasses1.add(Dense(512, activation='relu'))\n",
    "model_glasses1.add(BatchNormalization())\n",
    "model_glasses1.add(Dropout(0.5))\n",
    "model_glasses1.add(Dense(2, activation = 'softmax'))\n",
    "\n",
    "model_glasses1.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "model_glasses1.load_weights(\"glasses_model_1.h5\")\n",
    "\n",
    "#####################################################################\n",
    "model_glasses2 = Sequential()\n",
    "model_glasses2.add(Conv2D(32, kernel_size=(3, 3), activation = 'relu', input_shape = (128, 128, 3)))\n",
    "model_glasses2.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model_glasses2.add(Dropout(0.5))\n",
    "model_glasses2.add(Conv2D(64,kernel_size=(3, 3), activation='relu'))\n",
    "model_glasses2.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model_glasses2.add(Dropout(0.5))\n",
    "model_glasses2.add(Conv2D(128,kernel_size=(3, 3), activation='relu'))\n",
    "model_glasses2.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model_glasses2.add(Dropout(0.5))\n",
    "model_glasses2.add(Flatten())\n",
    "model_glasses2.add(Dense(512, activation='relu'))\n",
    "model_glasses2.add(Dropout(0.5))\n",
    "model_glasses2.add(Dense(2, activation = 'sigmoid'))\n",
    "model_glasses2.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "model_glasses2.load_weights(\"glasses_model_2.h5\")\n",
    "#####################################################################\n",
    "emotion_dict = {0: \"Angry\", 1: \"Disgusted\", 2: \"Fearful\", \n",
    "                3: \"Happy\", 4: \"Neutral\", 5: \"Sad\", 6: \"Surprised\"}\n",
    "\n",
    "\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from skimage import transform\n",
    "def load(filename):\n",
    "   np_image = Image.open(filename)\n",
    "   np_image = np.array(np_image).astype('float32')/255\n",
    "   np_image = transform.resize(np_image, (128, 128, 3))\n",
    "   np_image = np.expand_dims(np_image, axis=0)\n",
    "   return np_image\n",
    "\n",
    "\n",
    "file_path = 'C:/Users/face/'\n",
    "file_path = '../graduation_dataset/mask/test/'\n",
    "file_path = '../graduation_dataset/glasses/test_3/'\n",
    "file_path = 'C:/Users/example/'\n",
    "file_path = '../face-4263.png'\n",
    "\n",
    "\n",
    "image = load(file_path)\n",
    "result_skin = model\n",
    "result_mask1 = model_mask1.predict(image)\n",
    "result_glasses1 = model_glasses1.predict(image)\n",
    "print(file_path)\n",
    "if result_mask1[0][0] > result_mask1[0][1]:\n",
    "    print('해당 사진은 마스크를 썼습니다.')\n",
    "else:\n",
    "    image2 = cv2.imread(filepath)\n",
    "    faceAligned = face_align(image2)\n",
    "    np_image = Image.fromarray(cv2.cvtColor(faceAligned, cv2.COLOR_BGR2GRAY))\n",
    "    np_image = np.array(np_image).astype('float32')/255\n",
    "    np_image = transform.resize(np_image, (48, 48, 1))\n",
    "    np_image = np.expand_dims(np_image, axis=0)\n",
    "    result = model_emotion.predict(np_image)\n",
    "    print('예측: ' + filename)\n",
    "    maxindex = int(np.argmax(result))\n",
    "    print(emotion_dict[maxindex])\n",
    "        \n",
    "if result_glasses1[0][0] < result_glasses1[0][1]:\n",
    "    print('해당 사진은 안경을 쓰지않았습니다.')\n",
    "else:\n",
    "    #print('해당 사진은 안경을 썼습니다.')\n",
    "    result_glasses2 = model_glasses2.predict(image)\n",
    "    if max(result_glasses2[0]) == result_glasses2[0][0]:\n",
    "         print('해당 사진은 안경을 썼습니다.')\n",
    "    else:\n",
    "         print('해당 사진은 선글라스를 썼습니다.')\n",
    "        \n",
    "print('#####################################')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
